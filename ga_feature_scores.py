# -*- coding: utf-8 -*-
"""GA_Feature_Scores.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z9vX0vs9P30iVYlMyrWkEPr-ngvyiNxw
"""

# Mount google drive at /content/drive
from google.colab import drive
drive.mount('/content/drive')

!pip uninstall -y scikit-learn
!pip install scikit-learn==1.3.1
!pip install sklearn-genetic-opt

# Set seeds
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
import json
import pandas as pd
np.random.seed(42)
tf.random.set_seed(42)

# Read the contents of the first file
with open('/content/drive/MyDrive/BDDF_Research/approved_updated_proteins.txt', 'r') as file1:
    content1 = file1.read().splitlines()

# Read the contents of the second file
with open('/content/drive/MyDrive/BDDF_Research/investigational_proteins.txt', 'r') as file2:
    content2 = file2.read().splitlines()

# Combine the contents of both files and remove duplicates
merged_content = sorted(set(content1 + content2))

# Write the merged content to a new file
with open('merged.txt', 'w') as merged_file:
    for line in merged_content:
        merged_file.write(line + '\n')

print("Files merged successfully into 'merged.txt'.")

# Fetching PCP properties of druggable and non-druggable proteins
data_file_path = "/content/drive/MyDrive/protein_props.json"
druggable_proteins_file_path = "/content/drive/MyDrive/BDDF_Research/merged.txt"
approved_druggable_proteins_file_path = "/content/drive/MyDrive/BDDF_Research/approved_updated_proteins.txt"

with open(data_file_path, 'r') as f:
    protein_data = json.load(f)

print("Total number of uniprot human verified proteins:", len(protein_data))

with open(druggable_proteins_file_path, 'r') as f:
    druggable_proteins = f.read().splitlines()

with open(approved_druggable_proteins_file_path, 'r') as f:
    approved_druggable_proteins = f.read().splitlines()

print("Number of druggable proteins:", len(druggable_proteins))
print("Number of approved druggable proteins:", len(approved_druggable_proteins))

properties = (pd.read_json("/content/drive/MyDrive/protein_props.json")).transpose()
is_druggable = [1 if i in druggable_proteins else 0 for i in properties.index]
is_approved_druggable = [1 if i in approved_druggable_proteins else 0 for i in properties.index]

properties["is_druggable"] = is_druggable
properties["is_approved_druggable"] = is_approved_druggable

PCP_properties = properties.copy()
amino_acids = 'ACDEFGHIKLMNPQRSTVWY'
amino_acid_percent = {i:[] for i in amino_acids}
for i in PCP_properties['Amino Acid Percent']:
  for aa in amino_acids:
    amino_acid_percent[aa].append(i[aa])
for aa in amino_acids:
  PCP_properties = pd.concat([PCP_properties, pd.Series(amino_acid_percent[aa], index = PCP_properties.index, name = f"Amino Acid Percent {aa}")], axis = 1)

PCP_properties[f"Molar Extinction Coefficient 1"] = pd.Series([x[0] for x in PCP_properties['Molar Extinction Coefficient']], index = PCP_properties.index)
PCP_properties[f"Molar Extinction Coefficient 2"] = pd.Series([x[1] for x in PCP_properties['Molar Extinction Coefficient']], index = PCP_properties.index)

PCP_properties[f"Secondary Structure helix"] = pd.Series([x[0] for x in PCP_properties['Secondary Structure']], index = PCP_properties.index)
PCP_properties[f"Secondary Structure turn"] = pd.Series([x[1] for x in PCP_properties['Secondary Structure']], index = PCP_properties.index)
PCP_properties[f"Secondary Structure sheet"] = pd.Series([x[2] for x in PCP_properties['Secondary Structure']], index = PCP_properties.index)

PCP_properties.drop(columns = ['Amino Acid Count','Amino Acid Percent',"Molar Extinction Coefficient","Flexibility","Secondary Structure",'Sequence'], inplace = True)
PCP_properties['Sequence Length'] = PCP_properties['Sequence Length'].astype(int)
PCP_properties[['Molecular Weight', 'GRAVY', 'Isoelectric Point', 'Instability Index', 'Aromaticity', 'Charge at 7']] = PCP_properties[['Molecular Weight', 'GRAVY', 'Isoelectric Point', 'Instability Index', 'Aromaticity', 'Charge at 7']].astype(float)

with open("/content/drive/MyDrive/BDDF_Research/gdpc_encodings.json", 'r') as file:
    data = json.load(file)
gpdc_encodings = pd.DataFrame(data).transpose()

ppi = pd.read_json("/content/drive/MyDrive/ppi.json").transpose()
ppi_network = pd.read_csv("/content/drive/MyDrive/BDDF_Research/ppi_network_properties.csv")
ppi_network.index = ppi_network['Unnamed: 0']
ppi_network.drop(columns = ['Unnamed: 0'], inplace = True)
ppi = pd.concat([ppi, ppi_network], axis = 1)

glycolisation = pd.read_csv("/content/drive/MyDrive/glycosylation.csv")
glycolisation.index = glycolisation['Unnamed: 0']
glycolisation.drop(columns = ['Unnamed: 0'], inplace = True)
ptm = pd.read_csv("/content/drive/MyDrive/PTM_counts.csv")
ptm.index = ptm["Unnamed: 0"]
ptm.drop(columns = ['Unnamed: 0'], inplace = True)
ptm_counts = pd.concat([ptm, glycolisation], axis = 1)

with open("/content/drive/MyDrive/subcellular_locations2.json", 'r') as file:
    data = json.load(file)
unique_groups = set()
for entry in data.values():
    if "general" in entry:
        for general_entry in entry["general"]:
            if "group" in general_entry: unique_groups.add(general_entry["group"])

unique_groups_list = list(unique_groups)

rows = []
for protein_id in PCP_properties.index:
    row = {group: 0 for group in unique_groups_list}
    if protein_id in data:
        for entry in data[protein_id].get("general", []):
            if "group" in entry and entry["group"] in unique_groups:
                row[entry["group"]] = 1
    row["protein_id"] = protein_id
    rows.append(row)

subcellular_data = pd.DataFrame(rows).set_index("protein_id")

domains = pd.read_csv("/content/drive/MyDrive/BDDF_Research/data_top20_updated.csv")
domains.index = domains['Unnamed: 0']
domains.drop(columns = ['Unnamed: 0'], inplace = True)

flexibility = pd.read_csv("/content/drive/MyDrive/BDDF_Research/flexibility_properties.csv")
flexibility.index = flexibility['Unnamed: 0']
flexibility.drop(columns = ['Unnamed: 0'], inplace = True)

latent_data = pd.read_csv("/content/drive/MyDrive/BDDF_Research/latent_values.csv").transpose()
latent_data.columns = [f"Latent_Value_{i+1}" for i in latent_data.columns]
final_data = pd.concat([PCP_properties,gpdc_encodings, ptm_counts, ppi, subcellular_data, domains, flexibility, latent_data], axis = 1).dropna()
features_list = final_data.columns
y = final_data['is_approved_druggable']
features_list = features_list.drop(['is_druggable','is_approved_druggable'])
features_list = list(features_list)
print(features_list)
print(len(features_list))

#for splitting of data
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from imblearn.over_sampling import ADASYN, SMOTE

def get_data(x_sample, y_sample):
  return np.array(x_sample), np.array(y_sample)

def data_splitting(x_sample, y_sample, mode="default", scaler="none", class_size=600):
  druggable_indices = (y_sample == 1)  # Assuming 1 represents druggable
  non_druggable_indices = (y_sample == 0)  # Assuming 0 represents non-druggable

  druggable_X = x_sample[druggable_indices]
  druggable_y = y_sample[druggable_indices]

  non_druggable_X = x_sample[non_druggable_indices]
  non_druggable_y = y_sample[non_druggable_indices]

  druggable_X_remaining, druggable_X_test, druggable_y_remaining, druggable_y_test = train_test_split(druggable_X, druggable_y, test_size=class_size, random_state=123)
  non_druggable_X_remaining, non_druggable_X_test, non_druggable_y_remaining, non_druggable_y_test = train_test_split(non_druggable_X, non_druggable_y, test_size= class_size, random_state=123)

  X_test = pd.concat((druggable_X_test, non_druggable_X_test))
  y_test = pd.concat((druggable_y_test, non_druggable_y_test))
  X_train = pd.concat((druggable_X_remaining, non_druggable_X_remaining))
  y_train = pd.concat((druggable_y_remaining, non_druggable_y_remaining))
  X_train, y_train = shuffle(X_train, y_train, random_state=123)
  if mode == "default":
    pass
  elif mode == "adasyn":
    ada = ADASYN(random_state=42)
    X_train, y_train = ada.fit_resample(X_train, y_train)
  elif mode == "smote":
    smt = SMOTE(random_state=42)
    X_train, y_train = smt.fit_resample(X_train, y_train)

  if scaler == "std":
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
  elif scaler == "minmax":
    scaler = MinMaxScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
  elif scaler == "none":
    pass

  return X_train, X_test, y_train, y_test

# rem-new-data is to extract only those proteins which are either approved druggable or non-druggable
# i.e., it excludes proteins which are non-approved but druggable
new_data = final_data.copy()
new_data['new_column'] = new_data['is_druggable'] + new_data['is_approved_druggable']
rem_new_data = new_data[new_data['new_column'] != 1]
rem_new_data.shape, np.bincount(rem_new_data['new_column'])

X, y = rem_new_data[features_list], np.array(rem_new_data["is_approved_druggable"])

X_train, X_test, y_train, y_test = data_splitting(rem_new_data[features_list], rem_new_data["is_approved_druggable"],mode = "scaler", class_size=600)

X_train_druggable = X_train[y_train == 1]
print(X_train_druggable.shape)
X_train_non_druggable = X_train[y_train == 0]
print(X_train_non_druggable.shape)

X_train_non_druggable_partitions = np.array_split(X_train_non_druggable, int(len(X_train_non_druggable)/len(X_train_druggable)))
print(f"Splitting into {len(X_train_non_druggable_partitions)} partitions")

import xgboost as xgb
estimator_0_features = np.array([True, True, False, True, False, False, True, False, True, False, False, True, True, True, True, False, True, True, True, False, False, True, True, False, True, True, False, False, True, False, True, True, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, True, True, True, False, True, True, True, False, False, False, False, False, True, True, False, True, False, True, True, False, False, False, False, False, False, True, True, False, True, False, False, True, True, True, True, False, False, True, False, False, False, False, False, False, True, False, True, False, True, False, False, False, False, True, True, True, True, True, True, True, True, False, False, True, False, False, False, False, False, True, True, True, False, True, False, True, True, False, True, False, True, True, True, False, True, False, False, True, False, True, True, True, False, True, False, False, False, True, True, True, False, False, True, False, True, True, True, False, True, False, True, False, True, True, False, True, False, True, False, True, True, True, True, False, False, False, True, True, False, False
])
estimator_1_features = np.array([False, True, True, True, False, False, True, False, True, True, False, False, True, False, True, False, False, True, False, False, True, True, True, False, False, False, True, False, True, False, False, True, True, True, True, False, True, False, True, False, True, True, False, True, True, True, False, True, False, True, True, False, False, True, False, True, False, True, False, True, True, True, False, True, True, False, False, True, False, False, False, False, True, True, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, False, True, False, False, False, True, False, True, False, True, True, True, False, False, True, True, False, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, False, False, True, False, False, True, True, True, False, False, False, True, False, True, True, True, True, False, False, False, False, True, True, False, True, False, False, True, False, True, True, False, False, False, False, False, False, True, False, False, True, False, False, True, False, True, False, False, True, False, True, True, False, True, False, True, False, True, True, False, False
])
estimator_2_features = np.array([True, True, True, True, True, True, False, False, False, True, False, False, True, False, False, True, False, True, True, False, True, True, True, True, False, False, False, True, False, True, False, False, False, True, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, True, False, True, False, True, False, False, False, False, True, False, False, False, False, False, True, True, True, False, True, False, True, True, False, True, False, True, True, True, True, False, True, True, True, False, False, True, True, True, False, True, False, True, True, False, True, False, False, True, False, True, False, False, False, True, False, True, True, True, False, True, True, True, False, False, True, True, False, True, True, True, False, False, True, True, True, True, False, False, True, True, False, False, True, True, True, False, True, True, True, False, True, False, True, True, True, True, False, True, True, False, False, False, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, False, True, True, False, True, False, True, True])
estimator_3_features = np.array([False, True, True, True, True, True, False, True, True, True, False, False, False, False, True, False, True, True, False, False, False, False, True, False, True, False, True, True, True, True, False, True, False, False, False, True, False, True, False, True, True, False, True, False, True, True, True, True, False, True, False, True, True, True, False, True, True, True, True, True, False, True, True, False, False, True, True, True, True, False, False, True, True, True, False, False, True, True, False, True, True, False, True, True, True, False, False, True, True, True, True, True, False, False, True, True, True, False, True, False, True, True, False, True, True, False, True, False, True, True, True, True, True, False, True, True, True, False, True, True, False, False, False, True, False, True, True, True, True, False, True, True, False, True, False, True, True, True, True, True, False, True, True, True, False, False, True, True, False, False, True, True, False, True, True, True, True, False, False, True, False, True, False, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True])
estimator_4_features = np.array([True, True, True, True, False, False, True, True, True, False, False, True, True, False, True, True, True, True, False, True, False, False, False, False, True, True, False, True, True, True, True, False, False, False, False, False, True, True, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, True, False, True, True, True, True, False, True, False, True, False, False, True, True, True, True, False, True, True, False, True, False, False, False, True, True, False, False, False, True, True, True, True, True, True, True, False, False, True, False, False, True, False, True, False, False, True, False, True, True, False, False, False, True, True, True, True, True, False, False, True, False, True, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, False, False, False, False, True, False, False, False, True, True, True, False, False, False, False, True, False, False, True, False, True, True, True, True, True, False, False, True, False, True, False, False, True, True, False, True, False, True, False, False, False, True, False, True, False, True, True, False, True, False
])

estimator_5_features = np.array([True, True, True, False, False, True, False, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, False, True, True, False, True, False, False, True, False, True, True, True, False, True, True, True, False, False, True, False, True, False, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, False, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, False, False, False, False, False, True, False, False, False, False, True, True, True, False, True, True, False, False, False, False, True, True, True, True, False, False, False, True, True, True, False, False, True, False, False, False, True, True, False, False, False, False, False, False, True, True, True, True, False, True, True, False, False, True, False, False, True, True, True, True, False, False, False, False, False, False, True, False, False, False, True, True, False, False, False, False, True, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, False, False, True, True
])

estimator_6_features = np.array([False, True, False, False, True, False, False, True, False, True, True, True, True, True, False, False, True, False, False, True, True, True, False, False, False, False, False, False, True, True, True, True, True, False, False, False, False, True, False, True, False, True, True, True, True, True, False, False, True, False, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, False, True, False, False, True, False, True, True, True, True, False, True, False, True, True, True, False, True, True, False, True, True, True, False, True, False, False, True, False, True, True, False, False, False, True, False, True, False, True, True, True, True, False, True, False, True, True, False, False, False, False, True, False, True, False, False, True, True, False, False, True, True, False, True, False, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, False, False, False, False, True, True, False, False, True, True, False, True, False, True, True, True, True, False, True, False, False, False, False, False, True, False])

estimator_7_features = np.array([True, True, False, True, True, True, False, False, True, True, True, False, False, True, False, False, False, False, False, True, True, False, False, True, False, True, False, True, True, True, False, True, True, False, True, False, False, False, True, False, False, False, False, False, False, False, True, True, False, True, True, True, False, False, True, True, True, True, False, True, True, False, False, True, True, True, False, True, False, True, True, False, True, False, False, False, True, False, True, True, False, True, True, True, False, False, True, True, False, False, True, True, False, False, False, False, True, False, False, True, False, False, True, False, True, False, False, True, False, True, False, True, True, True, False, True, False, True, True, False, False, True, True, True, False, False, True, False, True, True, True, True, False, True, False, True, False, False, False, True, True, True, False, True, True, True, False, True, False, True, True, True, False, True, True, True, True, False, True, False, True, True, False, True, True, False, False, False, False, True, True, False, False, False, False, True, False, False, False, False, True, False, False]
)

estimator_8_features = np.array([False, True, True, True, True, False, True, False, True, True, False, True, True, False, False, False, False, False, True, False, True, True, False, True, False, True, True, False, True, False, False, True, True, True, False, True, True, False, False, False, True, False, True, False, True, True, True, False, True, True, True, False, True, False, True, True, True, True, False, True, False, True, False, True, False, True, True, True, False, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, True, True, False, False, True, True, False, False, True, True, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, True, True, True, True, False, False, False, False, False, True, True, False, False, False, True, False, False, True, False, True, False, False, True, False, True, True, False, False, True, True, False, True, False, True, True, True, False, True, False, False, False, True, True, True, True, True, True, True, False, False, True, False, False, True, False, True, False, False, True, False, False, False, True, True, False, False, True, False, True])

okk = [estimator_0_features,estimator_1_features,estimator_2_features,estimator_3_features,estimator_4_features, estimator_5_features, estimator_6_features, estimator_7_features, estimator_8_features]

models_list = []
for i, partition in enumerate(X_train_non_druggable_partitions):
    X_combined = np.concatenate((X_train_druggable, partition))
    y_combined = np.concatenate((np.ones(len(X_train_druggable)), np.zeros(len(partition))))

    clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42)

    print(len(okk[i]))
    X_combined = X_combined[:, okk[i]]
    clf.fit(X_combined, y_combined)
    models_list.append(clf)

y_preds = []
for i,model in enumerate(models_list):
  y_pred = model.predict(np.asarray(X_test)[:, okk[i]])
  y_preds.append(y_pred)

majority_preds = np.mean(y_preds, axis=0)
majority_preds = np.round(majority_preds)

from sklearn.metrics import accuracy_score
accuracy_metrics = {}
for i, y_pred in enumerate(y_preds):
  accuracy_metrics[f"partition_{i}"]={
      "accuracy_total": accuracy_score(y_test, y_pred),
      "accuracy_druggable": accuracy_score(y_test[y_test == 1], y_pred[y_test == 1]),
      "accuracy_non_druggable": accuracy_score(y_test[y_test == 0], y_pred[y_test == 0]),
  }

accuracy_metrics["majority"] = {
    "accuracy_total": accuracy_score(y_test, majority_preds),
    "accuracy_druggable": accuracy_score(y_test[y_test == 1], majority_preds[y_test == 1]),
    "accuracy_non_druggable": accuracy_score(y_test[y_test == 0], majority_preds[y_test == 0]),
}

df = pd.DataFrame(accuracy_metrics).transpose()
print(df)